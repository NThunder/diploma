\section{Заключение}
\label{sec:Chapter5} \index{Chapter5}

Проведенное исследование продемонстрировало эффективность применения стратегий маскирования для semi-supervised обучения моделей оптического распознавания символов (OCR) на японском языке. Анализ шести различных архитектур, реализующих маскирование на уровне патчей изображения и/или входных представлений декодера, показал, что все они превосходят по точности распознавания baseline модель, не использующую маскирование.

\subsection{Ключевые выводы}
\begin{enumerate}
  \item Маскирование как эффективный метод аугментации данных: Применение стратегий маскирования способствует изучению модели более обобщенных и устойчивых представлений, что подтверждается превосходством всех архитектур с маскированием над baseline.

  \item Синергетический эффект комбинированного подхода: Совместное маскирование патчей изображения и представлений декодера демонстрирует наилучшую точность распознавания, подчеркивая потенциал комбинирования разных подходов к маскированию.

  \item Перспективность маскирования представлений декодера: Архитектуры, маскирующие входные представления декодера, продемонстрировали высокую эффективность, превосходя даже методы с маскированием изображений. 
\end{enumerate}

\subsection{Направления для дальнейших исследований}

\begin{itemize}
  \item Оптимизация параметров маскирования: Дальнейшее изучение влияния размера маскируемых патчей, значения mask ratio и других параметров на эффективность обучения.

  \item Применение к другим языкам и наборам данных: Оценка эффективности исследованных подходов на более широком спектре языков и типов данных.

  \item Разработка новых стратегий маскирования: Исследование более сложных и адаптивных методов маскирования, учитывающих специфику задачи OCR и структуру языка. 
\end{itemize}
Полученные результаты открывают новые возможности для развития более точных и эффективных систем OCR, что имеет высокую практическую значимость для многих областей, связанных с автоматизацией обработки текстовой информации.
\newpage