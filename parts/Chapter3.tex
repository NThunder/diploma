\section{Исследование и построение решения задачи}
\label{sec:Chapter3} \index{Chapter3}

Для решения поставленной задачи – сравнительный анализ стратегий маскирования для semi-supervised предобучения моделей OCR – проведем декомпозицию на более мелкие подзадачи и представим результаты исследования предметной области.

\subsection{Исследование предметной области и существующих решений}

В данном разделе рассматриваются ключевые идеи из литературы, используемый набор данных и выбранные метрики оценки.

\begin{enumerate}
   \item \textbf{Обзор литературы и выбор архитектур:}
   Анализ существующих работ по применению методов маскирования в задачах компьютерного зрения и распознавания текста позволил выявить следующие перспективные идеи:
   \begin{itemize}
     \item Архитектура MAE \cite{he2021masked}: Применение самообучения (self-supervised learning) с реконструкцией замаскированных патчей изображения демонстрирует высокую эффективность в задачах CV. Данный подход будет реализован в методе 1.

     \item Архитектура SimMIM \cite{xie2021simmim}: Предложенное упрощение MAE, заключающееся в подаче на вход энкодера как видимых, так и маскированных патчей, позволяет сократить сложность модели, но требует больше вычислительных ресурсов. Эта идея будет использована в методе 2.
   
     \item Архитектура SupMAE \cite{gao2022supmae}: Использование размеченных данных для обучения MAE, как показано в данной работе, может значительно повысить эффективность предобучения. Данный подход будет реализован в методе 3. 

     \item Маскирование входных представлений декодера: Вдохновленные работой "Lacuna Reconstruction" \cite{stammer2023lacuna}, предлагающей маскировать части представлений на выходе из энкодера, мы исследуем маскирование входных представлений декодера. Комбинируя эту идею с MAE и SimMIM, получим методы 4 и 5. 
     
     \item Совместное маскирование патчей изображения и входных представлений декодера: Работы MaskOCR \cite{lyons2022masked} и MVLT \cite{lyons2022masked}, демонстрирующие эффективность совместного обучения на замаскированных изображениях и текстовых последовательностях, побудили нас исследовать комбинацию маскирования на разных уровнях модели. Эта идея будет реализована в методе 6.
   \end{itemize}


   \item \textbf{Датасет:}
   Для обучения и оценки моделей будет использован приватный датасет с изображениями, содержащими печатные надписи на японском языке. 

   Тренировочная выборка: 2 миллиона изображений.

   Тестовая выборка: 150 тысяч изображений.

   \begin{figure}[H]
     \centering
     \includegraphics[scale=1]{test_data.png}
     \caption{Пример изображения с печатным текстом из тестового набора данных.}
   \end{figure}
   

   \item \textbf{Выбор метрик оценки:}
   Для оценки качества OCR-моделей будут использоваться следующие метрики:
   \begin{itemize}
     \item Character Accuracy на основе Edit Distance: Данная метрика позволит оценить точность распознавания на уровне символов с учетом расстояния Левенштейна.
     \item Fragment Accuracy: Эта метрика будет использоваться для оценки точности распознавания на уровне фрагментов текста, что позволит более детально проанализировать работу моделей.
   \end{itemize}
\end{enumerate}

\subsection{Разработка и реализация baseline-модели}

\begin{enumerate}
   \item \textbf{Выбор базовой архитектуры:}
   В условиях ограниченных вычислительных ресурсов и с целью оптимизации экспериментальной работы в качестве базовой архитектуры была выбрана модель Encoder-Decoder, представленная на Рисунке \ref{2}. В качестве энкодера и декодера была использована архитектура ViT \cite{dosovitskiy2020image} с четырьмя слоями, размерностью скрытого состояния 256 и размерностью feedforward 1024. 

    \begin{figure}[h!]
     \includegraphics[scale=1]{baseline.png}
     \caption{ Архитектура baseline-модели. Изображение разбивается на патчи размером 16x16 пикселей. Каждый патч подается на вход энкодеру. Выход декодера передается на вход линейному слою, который отображает каждое внутреннее представление декодера в вектор размерности, равной мощности алфавита.}
     \label{2} 
   \end{figure}
   \item \textbf{Реализация модели:}
   Программный код baseline-модели реализован на основе внутреннего фреймворка, предоставленного кафедрой. Фреймворк базируется на модулях PyTorch и PyTorch Lightning.
   В качестве функции потерь выбрана функция Connectionist Temporal Classification Loss (CTC Loss) в связи с тем, что каждый патч изображения может содержать несколько символов или не содержать их вовсе.
   
   
   \item \textbf{Обучение и оценка baseline-модели:}
   Процесс обучения модели проводился в течение 80 эпох с размером батча, равным 64. Количество итераций обучения, обрабатываемых моделью за одну эпоху, составило 20000.

   Результаты оценки модели:
   \begin{itemize}
     \item CharAcc (точность распознавания символов): 95.8\%
     \item FragAcc (точность распознавания фрагментов текста): 79\%
   \end{itemize}
\end{enumerate}

\subsection{Разработка и реализация моделей с маскированием}


\subsubsection{Маскирование патчей изображения}
В рамках исследования были изучены три метода маскирования патчей изображения для обучения моделей OCR с использованием подходов, основанных на автоэнкодерах. 
\begin{itemize}
   \item Метод 1: Маскирование с реконструкцией (MAE)
   
     Первый метод (Рисунок \ref{3}) основан на архитектуре (MAE) \cite{he2021masked}. Процесс обучения состоит из двух этапов: предварительного обучения (pretraining) и тонкой настройки (finetuning).
     \begin{itemize}
        \item Предварительное обучение:
        \begin{enumerate}
          \item Маскирование:
          
          Случайным образом выбирается определенный процент патчей изображения и заменяется нулями (маскируется). Позиции замаскированных патчей сохраняются.
          \item Кодирование: Незамаскированные патчи подаются на вход энкодера.
          \item Декодирование: К выходным данным энкодера добавляются замаскированные патчи, после чего информация передается на вход декодера.
          \item Реконструкция: Обучение модели осуществляется путем минимизации функции потерь среднеквадратичной ошибки между исходными значениями пикселей в замаскированных областях и значениями пикселей, предсказанными моделью (ММSE).
        \end{enumerate}
        \item Тонкая настройка:
        \begin{enumerate}
          \item Маскирование патчей изображения не производится.
          \item Модель обучается на задачу распознавания текста с использованием CTC Loss.
        \end{enumerate}

        Для каждого этапа используется отдельный декодер.

     \end{itemize}
     \begin{figure}[H]
        \centering
        \includegraphics[scale=1]{Arch1.png}
        \caption{Архитектура модели с маскированием патчей изображения (MAE).}
        \label{3} 
     \end{figure}

   \item Метод 2: Маскирование с полным входом (SimMIM)

   Второй метод (Рисунок \ref{4}) основан на архитектуре SimMIM \cite{xie2021simmim} и отличается от первого метода тем, что на вход энкодера подаются все патчи изображения, включая замаскированные. Остальные этапы предварительного обучения и тонкой настройки аналогичны методу 1.

   \begin{figure}[H]
     \centering
     \includegraphics[scale=1]{Arch2.png}
     \caption{Архитектура модели с маскированием патчей изображения (SimMIM).}
     \label{4} 
   \end{figure}

   \item Метод 3: Маскирование с совместным обучением (SupMAE)
   
   Третий метод, представленный на Рисунке \ref{5}, основан на архитектуре SupMAE \cite{gao2022supmae} и отличается от первого метода тем, что на этапе предварительного обучения модель обучается одновременно на двух функциях потерь: МMSE Loss для реконструкции маскированных частей изображения и CTC Loss для распознавания текста. Этап тонкой настройки аналогичен методам 1 и 2.

   \begin{figure}[H]
     \centering
     \includegraphics[scale=1]{Arch3.png}
     \caption{Архитектура модели с маскированием патчей изображения (SupMAE).}
     \label{5} 
   \end{figure}
\end{itemize}
   
\subsubsection{Маскирование входных представлений декодера}

В дополнение к маскированию патчей изображения, были исследованы два метода, основанные на маскировании входных представлений декодера.

\begin{itemize}

   \item Метод 4: Маскирование представлений декодера с CTC-обучением
   

   Четвертый метод (Рисунок \ref{6}) реализует идею маскирования входных представлений декодера и также состоит из двух этапов обучения:
   \begin{itemize}
     \item Предварительное обучение:
     \begin{enumerate}
        \item Формирование патчей: Изображение разбивается на патчи размером 16x16 пикселей.
        \item Кодирование: Патчи подаются на вход энкодера.
        \item Маскирование представлений: На выходе из энкодера, полученные промежуточные представления случайно маскируются (зануляются) с определенной вероятностью (mask ratio).
        \item Декодирование: Замаскированные представления передаются на вход декодера.
        \item Распознавание текста: Модель обучается с использованием CTC Loss.
     \end{enumerate}
     \item Тонкая настройка:
     \begin{enumerate}
        \item Маскирование представлений декодера не производится.
        \item Модель продолжает обучаться на задачу распознавания текста с использованием CTC Loss.
     \end{enumerate}
   \end{itemize}
   \begin{figure}[H]
     \centering
     \includegraphics[scale=1]{Arch_4.png}
     \caption{Архитектура модели с маскированием входных представлений декодера (CTC-обучение).}
     \label{6} 
   \end{figure}

   \item Метод 5: Маскирование представлений декодера с совместным обучением
   
   Пятый метод (Рисунок \ref{7}) отличается от четвертого тем, что на этапе предварительного обучения модель обучается одновременно на двух функциях потерь: CTC Loss для распознавания текста и МMSE Loss для реконструкции патчей, соответствующих маскированным входным представлениям декодера. Этапы тонкой настройки аналогичны методу 4.

   \begin{figure}[H]
     \centering
     \includegraphics[scale=1]{Arch5.png}
     \caption{Архитектура модели с маскированием входных представлений декодера (совместное обучение).}
     \label{7} 
   \end{figure}

\end{itemize}

\subsubsection{Комбинированное маскирование}
В рамках исследования был изучен метод, комбинирующий маскирование патчей изображения и входных представлений декодера.
\begin{itemize}
   \item Метод 6:
   
   Шестой метод (Рисунок \ref{8}) реализует идею совместного маскирования патчей изображения и входных представлений декодера. Процесс обучения также разделен на два этапа: предварительное обучение и тонкую настройку.

   \begin{itemize}
     \item Предварительное обучение:
     \begin{enumerate}
        \item Формирование и маскирование патчей: Изображение разделяется на патчи размером 16x16 пикселей. Случайным образом выбирается и маскируется определенный процент патчей (mask ratio).
        \item Кодирование: Патчи, как замаскированные, так и не замаскированные, подаются на вход энкодера.
        \item Маскирование представлений: На выходе из энкодера полученные промежуточные представления также случайно маскируются с определенной вероятностью (mask ratio). 
        \item Декодирование: Замаскированные представления передаются на вход декодера.
        \item Распознавание текста: Модель обучается с использованием CTC Loss.
     \end{enumerate}
     \item Тонкая настройка:
     \begin{enumerate}
        \item Маскирование патчей изображения и представлений декодера не производится (mask ratio равен нулю).
        \item Модель продолжает обучаться на задачу распознавания текста с использованием CTC Loss.
     \end{enumerate}
   \end{itemize}

   \begin{figure}[H]
     \centering
     \includegraphics[scale=1]{Arch_6.png}
     \caption{Архитектура модели с совместным маскированием патчей изображения и входных представлений декодера.}
     \label{8} 
   \end{figure}
\end{itemize}

\subsection{Проведение экспериментов и анализ результатов}

Данный подраздел посвящен описанию проведенных экспериментов по сравнению различных стратегий маскирования для semi-supervised обучения моделей OCR на японском языке. Представлены результаты экспериментов и сформулированы выводы.

\begin{enumerate}
   \item  Обучение моделей с маскированием:
   
   Обучение моделей с различными стратегиями маскирования проводилось с использованием следующих параметров:

   Количество эпох:
   \begin{itemize}
     \item Предварительное обучение (pretraining): 60
     \item Тонкая настройка (finetuning): 60
   \end{itemize}
   
   Размер маскированного патча: 16x16 px

   \item Оценка качества моделей:
   
     Для оценки качества OCR-моделей были использованы метрики CharAcc (Character Accuracy) и FragAcc (Fragment Accuracy). Результаты представлены в Таблице 1. 
     \begin{table}[H]
        \scalebox{0.9}{
        \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        № метода & Маскирование & Pretrain & Mask ratio (\%) & CharAcc (\%) & FragAcc (\%)\\ \hline
        0(baseline) & нет & нет & 0 & 95.8 & 79 \\ \hline
        1 & Патчи изображения & МMSE & 25 & 96.2 & 80.2 \\ \hline
        1 & Патчи изображения & МMSE & 75 & 96.35 & 80.9 \\ \hline
        2 & Патчи изображения & МMSE & 75 & 96.25 & 80.5 \\ \hline
        3 & Патчи изображения & МMSE+CTC & 25 & 96.4 & 81.15 \\ \hline
        4 & Представления декодера & CTC & 75 & 96.45 & 81.34 \\ \hline
        5 & Представления декодера & МMSE+CTC & 25 & 96.4 & 81.2 \\ \hline
        6 & Комбинирование & CTC & 33 и 33 & 96.5 & 81.36 \\ \hline
        \end{tabular}
        }
        \caption{Сравнительный анализ эффективности различных стратегий маскирования на основе экспериментальных данных.}
     \end{table}

   \item Выводы:
   
   \begin{itemize}
     \item Применение стратегий маскирования оказывает положительное влияние на качество распознавания текста. Все рассмотренные методы, использующие маскирование, превзошли базовую модель по метрикам CharAcc и FragAcc, что свидетельствует об эффективности данного подхода при semi-supervised обучении.
     
     \item Маскирование на уровне патчей изображения с функцией потерь МMSE на этапе pretrain демонстрирует высокую эффективность. Наблюдается тенденция к улучшению показателей качества распознавания с увеличением доли маскируемых патчей.
     
     \item Различные архитектуры моделей с маскированием патчей изображения демонстрируют сравнимые результаты.

     \item Введение функции потерь CTC в процесс обучения с маскированием, как на уровне патчей изображения, так и на уровне представлений декодера, позволяет получить дополнительный прирост точности.
     
     \item Маскирование на уровне представлений декодера, особенно с использованием функции потерь CTC, показало себя более эффективным, чем маскирование патчей изображения. Данный результат указывает на перспективность использования маскирования на более высоких семантических уровнях при обучении OCR-моделей.

     \item Наилучшие результаты были достигнуты при комбинировании маскирования на уровне патчей изображения и на уровне представлений декодера, что подтверждает гипотезу о целесообразности совместного использования различных подходов к маскированию.

   \end{itemize}

   Полученные результаты свидетельствуют об успешном решении поставленной задачи. Разработаны и исследованы различные стратегии маскирования для semi-supervised обучения моделей OCR на японском языке. 
\end{enumerate}

\newpage
