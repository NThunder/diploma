\section{Исследование и построение решения задачи}
\label{sec:Chapter3} \index{Chapter3}

Для решения поставленной задачи – сравнительный анализ стратегий маскирования для semi-supervised предобучения моделей STR – проведем декомпозицию на более мелкие подзадачи.

\subsection{Исследование предметной области и существующих решений}



\begin{enumerate}
     \item  \textbf{Обзор литературы:}
     \begin{itemize}
          \item Архитектура MAE показывает довольно хорошие результаты в задачах CV, за счёт self-supervised подхода. Реализуем эту идею в архитектуре $1$.

          \item Архитектура SimMIM наводит на мысль, что на вход энкодеру можно подавать не только видимые патчи изображения, но и маскированные, это значительно упрощает архитектуру по сравнению с MAE, но требует гораздо больше памяти и времени для стадии pretrain. Реализуем эту идею в архитектуре $2$.
      
          \item Как было показано в статье SupMAE, использование размеченных данных для обучения MAE может значительно улучшить его эффективность, Реализуем эту идею в архитектуре $3$. 

          \item Статья Lacuna Reconstruction наводит нас на мысль, что так же можно маскировать входные представления декодера. Скрестив эту идею с предыдущими двумя получим архитектуры $4$ и $5$.
          
          \item Статьи MaskOCR и MVLT навели нас на мысль, что можно скрестить маскирование  патчей  изображения и входных представлений декодера, что дало нам архитектуру $6$.
     \end{itemize}


     \item  \textbf{Датасет:}
      У нас имеется внутренний размеченный датасет с печатанными надписями на японском языке. Тренировочная выборка содержит приблизительно 2 миллиона картинок. Тестовая выборка содержит приблизительно 150 тысяч картинок.
      \begin{figure}[h!]
          \centering
          \includegraphics[scale=1]{test_data.png}
          \caption{Пример надписи из тестового набора данных}
      \end{figure}
     

     \item  \textbf{Выбор  метрик  оценки:}
      Для  оценки  качества  наших OCR моделей будем использовать метрику CharAcc, основанную на Edit Distance. Так же будем использовать метрику Fragment Accuracy.
\end{enumerate}

\subsection{Разработка и реализация  baseline-модели}

\begin{enumerate}
     \item  \textbf{Выбор  базовой  архитектуры:}
       В силу ограниченности вычислительных ресурсов и для удобного проведения экспериментов в качестве базовой модели была выбрана архитектура Encoder-Decoder проилюстрированная на Рисунке 2. В качестве энкодера и декодера была выбрана архитектура ViT в 4 слоями, размером скрытого состояния равным 256 и размерностью feedforward равным 1024.

       \begin{figure}[h!]
          \includegraphics[scale=1]{baseline.png}
          \caption{Архитектура для baseline модели. Изображение делится на патчи размером 16 на 16 пикселей. Затем каждый патч поступает на вход энкодеру. Выход из декодера подается на вход линейному слою, который отображает каждое внутреннее представление декодера в вектор с размерностью алфавита.}
      \end{figure}
     \item  \textbf{Реализация  модели:}
      Код  для  baseline-модели  написан на базе внутреннего фреймворка, предоставленного кафедрой. Фреймворк основывается на таких модулях, как PyTorch и PyTorch Lighting.
      В качестве функции потерь выбран Connectionist Temporal Classification Loss, так как каждый патч может содержать несколько символов или не содержать их вовсе.
      
     \item  \textbf{Обучение и оценка baseline-модели:}
      Обучение  модели производилось в течении 80 эпох с размером бача равным 64. Количество батчей данных, которые модель обрабатывает за одну эпоху обучения 20000.

      Значения метрик: CharAcc: 95.8\%, FragAcc: 79\%.
\end{enumerate}

\subsection{Разработка и реализация моделей с  маскированием}

\begin{enumerate}
     \item  \textbf{Маскирование патчей  изображения:}
     \begin{itemize}
          \item Первый  метод основан на статье MAE, Рисунок 3. Обучение происходит в 2 этапа. Сначала определенный процент(mask ratio) патчей изображения маскируется(зануляется), их позиции запоминаются, затем видимые патчи подаются на вход энкодеру, на выходе из энкодера добавляются маскированные патчи, затем всё подаётся на вход декодеру.
               На стадии pretrain модель обучается на задачу реконструкции изображения с помощью MSE Loss, затем на стадии finetune патчи перестают маскироваться и модель обучается с помощью CTC Loss.
               Для каждой задачи обучается свой декодер.
               \begin{figure}[H]
                    \centering
                    \includegraphics[scale=1]{Arch1.png}
                    \caption{Архитектура 1}
               \end{figure}

          \item Второй метод основан на статье SimMIM, Рисунок 4. Отличие от Архитектуры 1 в том, что на вход энкодеру подаются все патчи, независимо от того маскированные они или нет. 

          \begin{figure}[H]
               \centering
               \includegraphics[scale=1]{Arch2.png}
               \caption{Архитектура 2}
          \end{figure}

          \item Третий метод основан на статье SupMAE, Рисунок 5. Отличие от Архитектуры 1 в том, что на стадии pretrain модель одновременно обучается сразу на две функции потерь(CTC Loss и MSE loss). 

          \begin{figure}[H]
               \centering
               \includegraphics[scale=1]{Arch3.png}
               \caption{Архитектура 3}
          \end{figure}
     \end{itemize}
       
     \item  \textbf{Маскирование входных  представлений  декодера:}
     \begin{itemize}
          \item Четвёртый  метод основан на идее маскирования входных  представлений  декодера, Рисунок 6. Обучение происходит в 2 этапа. Сначала Изображение делится на патчи размером 16 на 16 пикселей. Патчи подаются на вход энкодеру, на выходе из энкодера промежуточные представления случайно маскируются(зануляются) с определенным процентом(mask ratio), Всё подаётся на вход декодеру.
               На стадии pretrain модель обучается с помощью CTC Loss, затем на стадии finetune патчи перестают маскироваться и модель продолжает обучается на задачу распознавания текста.
               Для каждой задачи обучается свой декодер.
               \begin{figure}[H]
                    \centering
                    \includegraphics[scale=1]{Arch_4.png}
                    \caption{Архитектура 4}
               \end{figure}

          \item В пятом методе, Рисунок 7,  в отличии от Архитектуры 4, на стадии pretrain модель одновременно обучается сразу на две функции потерь(CTC Loss и MSE loss). 

          \begin{figure}[H]
               \centering
               \includegraphics[scale=1]{Arch5.png}
               \caption{Архитектура 5}
          \end{figure}

     \end{itemize}

     \item  \textbf{Комбинированное  маскирование:}
       \begin{itemize}
          \item Шестой  метод основан на идее совмещения  маскирования  патчей  изображения  и  входных  представлений  декодера, Рисунок 8. Обучение по прежнему происходит в 2 этапа. Сначала Изображение делится на патчи размером 16 на 16 пикселей. Определенный процент(mask ratio) патчей изображения маскируется. Патчи подаются на вход энкодеру, на выходе из энкодера промежуточные представления также случайно маскируются с определенным процентом(mask ratio), Всё подаётся на вход декодеру.
               На обоих стадиях модель обучается с помощью CTC Loss. Стадия finetune отличается от pretrain тем, что mask ratio равен нулю.
               \begin{figure}[H]
                    \centering
                    \includegraphics[scale=1]{Arch_6.png}
                    \caption{Архитектура 6}
               \end{figure}
     \end{itemize}
\end{enumerate}

\subsection{Проведение  экспериментов  и  анализ  результатов}

\begin{enumerate}
     \item   Обучение  моделей  с  маскированием:
     \begin{itemize}
          \item  Колличество эпох для стадии pretrain для каждой архитектуры: 60
          \item  Колличество эпох для стадии finetune для каждой архитектуры: 60
          \item  Размер маскированного патча: 16x16 px
     \end{itemize}

     \item  Оценка  качества  моделей:
          \begin{table}[H]
               \begin{tabular}{|c|c|c|c|c|}
               \hline
               № архитектуры & Маскирование & Mask ratio (\%) & CharAcc (\%) & FragAcc (\%) \\ \hline
               0(baseline) & нет & 0 & 95.8 & 79 \\ \hline
               1 & Патчи изображения & 25 & 96.2 & 80.2 \\ \hline
               1 & Патчи изображения & 75 & 96.35 & 80.9 \\ \hline
               2 & Патчи изображения & 75 & 96.25 & 80.5 \\ \hline
               3 & Патчи изображения & 25 & 96.4 & 81.15 \\ \hline
               4 & Представления декодера & 75 & 96.45 & 81.34 \\ \hline
               5 & Представления декодера & 25 & 96.4 & 81.2 \\ \hline
               6 & Комбинирование & 33 и 33 & 96.5 & 81.36 \\ \hline
               \end{tabular}
          \end{table}

     \item  Формулировка  выводов:
     \begin{itemize}
          \item Маскирование патчей изображения позволяет улучшить точность распознавания
               текста по сравнению с обучением без маскирования. Разные архитектуры моделей с
               маскированием патчей могут демонстрировать сравнимые результаты.
          \item Маскирование входных представлений декодера также эффективно для повышения
               точности распознавания текста. Данный подход показал себя более эффективным, чем
               маскирование патчей изображения.
          \item Комбинация разных стратегий маскирования позволяет добиться наибольшей точности распознавания текста.
     \end{itemize}
     Полученные результаты свидетельствуют о том, что поставленная задача решена. Удалось разработать и исследовать различные стратегии маскирования для semi -
     supervised обучения моделей STR на японском языке. Все исследованные стратегии
     маскирования превзошли baseline модель по точности распознавания текста. Наилуч
     ший результат был достигнут при комбинировании маскирования патчей изображения
     и входных представлений декодера.
\end{enumerate}

\newpage
