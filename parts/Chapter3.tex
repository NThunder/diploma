\section{Исследование и построение решения задачи}
\label{sec:Chapter3} \index{Chapter3}

Декомпозиция задачи

Главная задача:Исследовать эффективность различных стратегий маскирования в semi-supervised обучении для повышения точности распознавания текста на изображениях (STR) на японском языке.

Подзадачи:

1. Подготовка данных:

1.1. Сбор и предобработка датасета:
    Найти  датасет  с  изображениями,  содержащими  печатный  текст  на  японском  языке  (если  не  будет  найден  подходящий,  рассмотреть  возможность  генерации  синтетических  данных). 
    Разделить  датасет  на  обучающую,  валидационную  и  тестовую  выборки.
    Провести  предобработку  изображений  (например,  приведение  к  единому  размеру,  нормализация). 
    Привести  текстовые  метки  к  единому  формату. 
1.2. Разработка  или  адаптация  инструментов  для  маскирования  данных:
     Создать  функции  для  маскирования  патчей  изображения  с  разными  размерами  и  mask ratio.
     Разработать  механизм  маскирования  входных  представлений  декодера  (например,  на  основе  случайного  обнуления  элементов  тензоров). 

2. Разработка и обучение моделей:

2.1.  Выбор  baseline  архитектуры  модели  STR:
    Изучить  существующие  архитектуры  моделей  STR  (например,  CRNN,  STAR-Net,  Vision Transformers).
    Выбрать  наиболее  подходящую  архитектуру,  учитывая  требования  к  точности,  скорости  работы  и  масштабируемости.
2.2. Реализация  разных  стратегий  маскирования:
    2.2.1. Маскирование  патчей  изображения:
         Встроить  маскирование  патчей  в  выбранную  архитектуру  модели  STR. 
         Экспериментировать  с  разными  размерами  патчей  и  mask ratio.
    2.2.2. Маскирование  входных  представлений  декодера:
         Реализовать  маскирование  входных  представлений  декодера  в  выбранной  архитектуре  модели.
          Экспериментировать  с  разными  способами  маскирования  и  mask ratio.
    2.2.3. Комбинирование  маскирования  патчей  и  входных  представлений:
         Объединить  маскирование  патчей  изображения  и  входных  представлений  декодера  в  единой  архитектуре  модели.
          Экспериментировать  с  разными  сочетаниями  параметров  маскирования.
2.3.  Обучение  моделей  с  разными  стратегиями  маскирования:
     Провести  предобучение  моделей  на  неразмеченных  данных  с  использованием  выбранной  функции  потерь (например,  MSE).
     Выполнить  дообучение  предобученных  моделей  на  размеченных  данных  с  использованием  CTCLoss.
     Настроить  гиперпараметры  моделей  (например,  скорость  обучения,  размер  батча)  с  помощью  валидационной  выборки.

3. Оценка и анализ результатов:

3.1. Оценка  качества  обученных  моделей:
     Оценить  точность  распознавания  текста  (CharAcc)  всех  обученных  моделей  на  тестовой  выборке. 
     Сравнить  результаты  моделей,  обученных  с  разными  стратегиями  маскирования,  с  baseline  моделью. 
3.2. Анализ  влияния  параметров  на  эффективность  моделей:
     Проанализировать  влияние  размера  патчей,  mask ratio  и  других  параметров  на  точность  распознавания  текста. 
     Исследовать  зависимость  эффективности  разных  стратегий  маскирования  от  объема  обучающих  данных.
3.3.  Интерпретация  результатов  и  формулировка  выводов:
     Объяснить  полученные  результаты  с  точки  зрения  особенностей  использованных  методов.
     Сформулировать  выводы  об  эффективности  разных  стратегий  маскирования  для  задачи  STR  на  японском  языке.
     Предложить  рекомендации  по  дальнейшему  развитию  исследования  и  применению  полученных  результатов. 

\newpage
