\section{Обзор существующих решений}
\label{sec:Chapter2} \index{Chapter2}

В данной главе рассматриваются существующие  решения  для  semi-supervised обучения моделей STR с использованием маскирования,  а также  оценивается  их соответствие  сформулированным требованиям.
1. Маскирование патчей изображения
Описание:Метод заключается в маскировании случайных патчей входного изображения, аналогично тому, как это делается в моделях Masked Autoencoders (MAE) [1] для задач компьютерного зрения.  Модель должна восстановить скрытые патчи на основе видимой информации.
Примеры:
[1] Masked Autoencoders Are Scalable Vision Learners (He et al., 2021)
[2] SimMIM: A Simple Framework for Masked Image Modeling (Xie et al., 2021)
Соответствие требованиям:
Эффективность: Метод  демонстрирует  хорошие  результаты  в  задачах  компьютерного  зрения,  однако  его  эффективность  для  STR  может  быть  ниже  из-за  того,  что  текст  имеет  более  структурированный  характер,  чем  общие  изображения.
Масштабируемость: Метод  хорошо  масштабируется  на  большие  наборы  данных  и  может  быть  эффективно  реализован  с  использованием  современных  GPU.
Интерпретируемость: Интерпретируемость  результатов  может  быть  ограничена  тем,  что  неясно,  какие  именно  признаки  модель  извлекает  из  частично  скрытого  изображения.

2. Маскирование входных представлений декодера

Описание: Этот  подход  заключается  в  маскировании  части  входных  представлений,  которые  декодер  получает  от  энкодера.  Декодер  должен  научиться  восстанавливать  замаскированные  части  на  основе  контекста.

Примеры:

[3]  Masked Sequence-to-Sequence Learning (Song et al., 2019)

Соответствие требованиям:

Эффективность: Метод  может  быть  эффективен  для  STR,  так  как  он  позволяет  модели  лучше  учитывать  контекст  при  распознавании  символов.
Масштабируемость: Масштабируемость  метода  зависит  от  конкретной  архитектуры  декодера.
Интерпретируемость: Интерпретируемость  результатов  также  может  быть  ограничена,  как  и  в  случае  с  маскированием  патчей  изображения.

3. Комбинирование  маскирования  патчей  изображения  и  входных  представлений  декодера
Описание: Этот  подход  сочетает  в  себе  маскирование  патчей  изображения  и  входных  представлений  декодера.
Примеры:
[4] Masked Vision-Language Transformers for Scene Text Recognition (Lyons et al., 2022)
Соответствие требованиям:
Эффективность: Комбинация  методов  потенциально  может  привести  к  наилучшим  результатам,  так  как  позволяет  модели  учитывать  как  локальную  информацию  (из  патчей  изображения),  так  и  глобальный  контекст  (из  входных  представлений  декодера).
Масштабируемость: Масштабируемость  метода  зависит  от  конкретной  архитектуры  модели  и  параметров  маскирования.
Интерпретируемость: Интерпретируемость  результатов  в  этом  случае  ещё  более  сложна,  чем  при  использовании  каждого  из  методов  по  отдельности.

Вывод

В  данной  главе  были  рассмотрены  существующие  подходы  к  применению  маскирования  в  semi-supervised  обучении  для  задачи  STR.  Каждый  из  методов  имеет  свои  преимущества  и  недостатки  с  точки  зрения  эффективности,  масштабируемости  и  интерпретируемости.  Выбор  оптимального  подхода  зависит  от  конкретной  задачи  и  набора  данных.  В  следующей  главе  будет  проведено  более  детальное  исследование  этих  методов  и  их  комбинаций. 

\newpage

